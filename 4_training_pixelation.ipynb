{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pixelation model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpdafRkBGpNK",
        "colab_type": "code",
        "outputId": "e095f3f0-f1bd-490c-d765-7782d949fb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoMq9X7MHBr6",
        "colab_type": "code",
        "outputId": "028ab424-e3ff-438d-ba42-b55b23feb0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Lambda\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import losses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGV4rfkFWxc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define constants and other set up\n",
        "image_size = (128, 128, 3)\n",
        "\n",
        "# set image data format manually to avoid potential confusion\n",
        "K.set_image_data_format('channels_last')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPdhV9xyHXpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perceptual loss\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_size)\n",
        "def perceptual_loss(y_true, y_pred):\n",
        "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "    loss_model.trainable = False\n",
        "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_EaCvL-Wv3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combining pixel and perceptual loss\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_size)\n",
        "def pixel_perceptual_loss(y_true, y_pred):\n",
        "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "    loss_model.trainable = False\n",
        "    perceptual=K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
        "    pixel= ((y_true-y_pred)**2)/(128*128*3)\n",
        "    combined_loss= (0.5*pixel) + perceptual\n",
        "    return (combined_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eojZdUfddTRS",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDdFCqlUHl2a",
        "colab_type": "code",
        "outputId": "cd800a83-972f-43e1-b761-aa421bf6992b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "input_img = Input(shape=image_size)  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoded = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(encoded)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "autoencoder = Model(input_img, decoded)\n",
        "#autoencoder.compile(optimizer='adam', loss=pixel_perceptual_loss, metrics = ['accuracy'])\n",
        "#autoencoder.compile(optimizer='adam', loss=perceptual_loss, metrics = ['accuracy'])\n",
        "#autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics = ['accuracy'])\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_497\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 128, 128, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 64, 64, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 64, 64, 32)        9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 128, 128, 3)       867       \n",
            "=================================================================\n",
            "Total params: 29,507\n",
            "Trainable params: 29,507\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_TDUipRdViV",
        "colab_type": "text"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_1YsvULH0Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  pickle_in = open('/content/drive/My Drive/Pickle/pixelated.pickle', 'rb') #lowest level of pixelation\n",
        "# X1 = pickle.load(pickle_in)\n",
        "# X2 = pickle.load(pickle_in)\n",
        "# X3 = pickle.load(pickle_in)\n",
        "# X4 = pickle.load(pickle_in)\n",
        "# X5 = pickle.load(pickle_in)\n",
        "# X6 = pickle.load(pickle_in)\n",
        "# X = np.concatenate((X1,X2, X3, X4, X5, X6))\n",
        "# del X1, X2, X3, X4, X5, X6\n",
        "\n",
        "# pickle_in = open('/content/drive/My Drive/Pickle/pixelated.pickle20', 'rb')\n",
        "# X1 = pickle.load(pickle_in)\n",
        "# X2 = pickle.load(pickle_in)\n",
        "# X3 = pickle.load(pickle_in)\n",
        "# X4 = pickle.load(pickle_in)\n",
        "# X5 = pickle.load(pickle_in)\n",
        "# X6 = pickle.load(pickle_in)\n",
        "# X = np.concatenate((X1,X2, X3, X4, X5, X6))\n",
        "# del X1, X2, X3, X4, X5, X6\n",
        "\n",
        "pickle_in = open('/content/drive/My Drive/Pickle/pixelated.pickle', 'rb')#highest level of pixelation\n",
        "X1 = pickle.load(pickle_in)\n",
        "# X2 = pickle.load(pickle_in)\n",
        "# X3 = pickle.load(pickle_in)\n",
        "# X4 = pickle.load(pickle_in)\n",
        "# X5 = pickle.load(pickle_in)\n",
        "# X6 = pickle.load(pickle_in)\n",
        "# X = np.concatenate((X1,X2, X3))\n",
        "# del X1, X2, X3\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCviSA_LNjg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(X1[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrHDZuPyNIXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle_in1 = open('/content/drive/My Drive/Pickle/original.pickle', 'rb')\n",
        "#y1 = pickle.load(pickle_in1)\n",
        "#y2 = pickle.load(pickle_in1)\n",
        "#y4 = pickle.load(pickle_in1)\n",
        "#y5 = pickle.load(pickle_in1)\n",
        "#y6 = pickle.load(pickle_in1)\n",
        "# y = np.concatenate((y1,y2,y3))\n",
        "# del y1,y2,y3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV1uaH7nO0Na",
        "colab_type": "code",
        "outputId": "7364dd0e-0e81-47de-8bfb-1c12f67c3989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMQnq2WxdZxB",
        "colab_type": "text"
      },
      "source": [
        "Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p3KhSdUWGAI",
        "colab_type": "code",
        "outputId": "258af786-0f9c-4d2f-8cec-c995b92c609d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "# split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6616, 128, 128, 3)\n",
            "(6616, 128, 128, 3)\n",
            "(5954, 128, 128, 3)\n",
            "(5954, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzfH2xIRcIdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=autoencoder.fit(X, y, epochs=8, batch_size=50, shuffle=True, validation_data=(X_test, y_test),)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYpHH5K18n8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.save('/content/drive/My Drive/Trained_models/combined30,again.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWwYzX-PBuTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.title('Loss / Combined Loss')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnuJgAO0dMwV",
        "colab_type": "text"
      },
      "source": [
        "Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tny556mB0Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 110\n",
        "predicted = autoencoder.predict(np.array([X_test[i]]))\n",
        "\n",
        "plt.imshow(X_test[i]) \n",
        "plt.show()\n",
        "plt.imshow(y_test[i]) # original\n",
        "plt.show()\n",
        "plt.imshow(predicted[0]) # predicted\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtW0eLDBcs4h",
        "colab_type": "text"
      },
      "source": [
        "SSIM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOQNJksectxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import data, img_as_float\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "predicted = autoencoder.predict(np.array([X_test[i]]))\n",
        "img=y_test[i]\n",
        "img_x=X_test[i]\n",
        "img_noise=predicted[0]\n",
        "ssim_noise = ssim(img, img_noise,\n",
        "                  data_range=img_noise.max() - img_noise.min(),multichannel=True)\n",
        "ssim_noise_new = ssim(img, img_x,\n",
        "                  data_range=img_x.max() - img_x.min(),multichannel=True)\n",
        "ssim_noise_original = ssim(img, img,\n",
        "                  data_range=img.max() - img.min(),multichannel=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPlKAhdYcw_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (ssim_noise)\n",
        "print (ssim_noise_new)\n",
        "print (ssim_noise_original)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo7gpfbQdHyg",
        "colab_type": "text"
      },
      "source": [
        "PSNR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtwuobMac2mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy \n",
        "import math\n",
        "import cv2\n",
        "original = y_test[i]\n",
        "predicted = autoencoder.predict(np.array([X_test[i]]))\n",
        "contrast = predicted[0]\n",
        "#contrast = y_test[2]\n",
        "#contrast = X_test[2]\n",
        "def psnr(img1, img2):\n",
        "    mse = numpy.mean((img1 - img2) ** 2 )\n",
        "    if mse == 0:\n",
        "      return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "\n",
        "d=psnr(original,contrast)\n",
        "print(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-I-IhZUdKr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-22YizNg8w-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo-a4CRIEE9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qktk5nn2A0Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}